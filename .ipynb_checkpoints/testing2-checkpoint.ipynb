{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f538a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Allen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Allen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff02d5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialData = pd.read_csv('dbb4c4ff1f31-CAC+2022_Training+Data+Set+New.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73e6cba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeOnes(df):\n",
    "    rev = list(df['trans_desc'])\n",
    "    for item in range(len(rev)):\n",
    "        rev[item] = re.sub(\" +\", \" \", rev[item])\n",
    "        rev[item] = re.sub(\"111111XXXXXX1111 111111111111111\", \"\", rev[item])\n",
    "        rev[item] = re.sub(\"\\?MCC=1111 11\", \"\", rev[item])\n",
    "        rev[item] = re.sub(\"111-111-1111\", \" \", rev[item])\n",
    "        rev[item] = re.sub(\"111-1111111\", \"\", rev[item])\n",
    "        rev[item] = re.sub(\"11111\", \"\", rev[item])\n",
    "        rev[item] = re.sub(\"\\?MCC=1111\", \"\", rev[item])\n",
    "        \n",
    "        \n",
    "    rev_location = list(df['default_location'])\n",
    "    rev_location = [str(p) for p in rev_location]\n",
    "    for item in range(len(rev_location)):\n",
    "        rev_location[item] = re.sub(\"111-111-1111\", \"\", rev_location[item])\n",
    "        rev_location[item] = re.sub(\"111-1111111\", \"\", rev_location[item])\n",
    "        rev_location[item] = re.sub(\"11111\", \"\", rev_location[item])\n",
    "        \n",
    "    \n",
    "        \n",
    "    for index, row in df.iterrows():\n",
    "        df.at[index, 'trans_desc'] = rev[index]\n",
    "        df.at[index, 'default_location'] = rev_location[index]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a3fe831",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialData = removeOnes(initialData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f611206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowerCaps(df):\n",
    "    df = df.applymap(lambda r: r.lower() if type(r) == str else r)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd9cb583",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialData = lowerCaps(initialData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8d924dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialData['numCat'] = (initialData['Category'].apply(lambda c: 0 if c == 'comunication services' \n",
    "                                                       else 1 if c == 'education' \n",
    "                                                       else 2 if c == 'entertainment' \n",
    "                                                       else 3 if c == 'finance' \n",
    "                                                       else 4 if c == 'health and community services' \n",
    "                                                       else 5 if c == 'property and business services' \n",
    "                                                       else 6 if c == 'retail trade' \n",
    "                                                       else 7 if c == 'services to transport' \n",
    "                                                       else 9 if c == 'travel' \n",
    "                                                       else 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06972647",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = initialData.iloc[:, [0,2,4,7,8,12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce479de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialData['congl2'] = initialData[new.columns[0:6]].apply(lambda x: ' | '.join(x.astype(str)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8737a7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sor</th>\n",
       "      <th>cdf_seq_no</th>\n",
       "      <th>trans_desc</th>\n",
       "      <th>merchant_cat_code</th>\n",
       "      <th>amt</th>\n",
       "      <th>db_cr_cd</th>\n",
       "      <th>payment_reporting_category</th>\n",
       "      <th>payment_category</th>\n",
       "      <th>is_international</th>\n",
       "      <th>default_brand</th>\n",
       "      <th>default_location</th>\n",
       "      <th>qrated_brand</th>\n",
       "      <th>coalesced_brand</th>\n",
       "      <th>Category</th>\n",
       "      <th>numCat</th>\n",
       "      <th>congl2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hh</td>\n",
       "      <td>t20110701260061756</td>\n",
       "      <td>recur debit crd pmt11/11 delta dental of a11 o...</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>58.34</td>\n",
       "      <td>d</td>\n",
       "      <td>card</td>\n",
       "      <td>debit card</td>\n",
       "      <td>False</td>\n",
       "      <td>delta dental of a11 of</td>\n",
       "      <td>ar</td>\n",
       "      <td>delta dental</td>\n",
       "      <td>delta dental</td>\n",
       "      <td>finance</td>\n",
       "      <td>3</td>\n",
       "      <td>hh | recur debit crd pmt11/11 delta dental of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sor          cdf_seq_no                                         trans_desc  \\\n",
       "0  hh  t20110701260061756  recur debit crd pmt11/11 delta dental of a11 o...   \n",
       "\n",
       "   merchant_cat_code    amt db_cr_cd payment_reporting_category  \\\n",
       "0             6300.0  58.34        d                       card   \n",
       "\n",
       "  payment_category  is_international           default_brand default_location  \\\n",
       "0       debit card             False  delta dental of a11 of               ar   \n",
       "\n",
       "   qrated_brand coalesced_brand Category  numCat  \\\n",
       "0  delta dental    delta dental  finance       3   \n",
       "\n",
       "                                              congl2  \n",
       "0  hh | recur debit crd pmt11/11 delta dental of ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialData[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84d3d5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(initialData.iloc[:, [15]])\n",
    "y = np.array(initialData.iloc[:, [14]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a893af1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove grammar, tokenize, and lemmatize the sentences\n",
    "def clean_sentences(df):\n",
    "    reviews = []\n",
    "\n",
    "    for sent in (df['congl2']):\n",
    "        \n",
    "        # remove non-alphabetical characters\n",
    "        text = re.sub('[^a-zA-Z]', ' ', sent)\n",
    "        \n",
    "        # tokenize sentence\n",
    "        words = word_tokenize(text.lower())\n",
    "        \n",
    "        # remove stop words:\n",
    "        new_words = [char for char in words if char.lower() not in stopwords.words('english')]\n",
    "        \n",
    "        # lemmatizing each word to its lemma\n",
    "        lem = WordNetLemmatizer()\n",
    "        lem_words = [lem.lemmatize(i) for i in new_words]\n",
    "    \n",
    "        reviews.append(lem_words)\n",
    "\n",
    "    return(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38e73e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sen = clean_sentences(initialData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a50d6126",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(train_sen,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1691ba52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29007\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "unique_words = set()\n",
    "len_max = 0\n",
    "\n",
    "for sent in (X_train):\n",
    "    \n",
    "    unique_words.update(sent)\n",
    "    \n",
    "    if(len_max<len(sent)):\n",
    "        len_max = len(sent)\n",
    "        \n",
    "print(len(list(unique_words)))\n",
    "print(len_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94638565",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(list(unique_words))\n",
    "embedding_dim = 300\n",
    "max_length = len_max\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "214dfc6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=len(list(unique_words)))\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7837f331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32000, 25) (8000, 25)\n"
     ]
    }
   ],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=len_max)\n",
    "X_test = pad_sequences(X_test, maxlen=len_max)\n",
    "\n",
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3150fae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23b03b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f3e84d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 11)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff3c0c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f154d846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Bidirectional,LSTM,Activation,Dropout,Flatten, Conv1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, MaxPooling1D\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56678fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(29218, 300, input_length = 25),\n",
    "    Conv1D(128, 2, padding='same',activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size = 2),\n",
    "    Dropout(0.2),\n",
    "    Conv1D(64, 2, padding='same',activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size = 2),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(32, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)),\n",
    "    Dropout(0.2),\n",
    "    Dense(11,activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c258f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(min_delta = 0.001,\n",
    "                               mode = 'max',\n",
    "                               monitor = 'val_accuracy',\n",
    "                               patience = 2)\n",
    "callback = [early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83c2e3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "125/125 [==============================] - 10s 72ms/step - loss: 4.3839 - accuracy: 0.4797 - val_loss: 4.8011 - val_accuracy: 0.0081\n",
      "Epoch 2/30\n",
      "125/125 [==============================] - 9s 73ms/step - loss: 2.2548 - accuracy: 0.7937 - val_loss: 3.9087 - val_accuracy: 0.0322\n",
      "Epoch 3/30\n",
      "125/125 [==============================] - 10s 77ms/step - loss: 1.2182 - accuracy: 0.9047 - val_loss: 2.9614 - val_accuracy: 0.2961\n",
      "Epoch 4/30\n",
      "125/125 [==============================] - 12s 93ms/step - loss: 0.7383 - accuracy: 0.9399 - val_loss: 2.1847 - val_accuracy: 0.5565\n",
      "Epoch 5/30\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.5058 - accuracy: 0.9546 - val_loss: 1.4687 - val_accuracy: 0.6619\n",
      "Epoch 6/30\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.3751 - accuracy: 0.9631 - val_loss: 1.2530 - val_accuracy: 0.6964\n",
      "Epoch 7/30\n",
      "125/125 [==============================] - 13s 106ms/step - loss: 0.2988 - accuracy: 0.9687 - val_loss: 1.3936 - val_accuracy: 0.6909\n",
      "Epoch 8/30\n",
      "125/125 [==============================] - 13s 107ms/step - loss: 0.2467 - accuracy: 0.9733 - val_loss: 1.4168 - val_accuracy: 0.7024\n",
      "Epoch 9/30\n",
      "125/125 [==============================] - 13s 105ms/step - loss: 0.2151 - accuracy: 0.9765 - val_loss: 1.4469 - val_accuracy: 0.7026\n",
      "Epoch 10/30\n",
      "125/125 [==============================] - 13s 107ms/step - loss: 0.1959 - accuracy: 0.9782 - val_loss: 1.5427 - val_accuracy: 0.6885\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "history = model.fit(X_train,y_train,\n",
    "                    validation_data = (X_test, y_test),\n",
    "                    epochs = num_epochs,\n",
    "                    batch_size = 256,\n",
    "                    verbose = 1,\n",
    "                    callbacks = callback)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
